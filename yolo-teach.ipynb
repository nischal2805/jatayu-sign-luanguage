{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup\n",
    "Install necessary packages (ultralytics, opencv-python, numpy) and import required libraries for working with YOLO models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics opencv-python numpy\n",
    "\n",
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# For displaying images in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Pre-trained Models\n",
    "Load pre-trained YOLOv8 models of various sizes (nano, small, medium, large, and xlarge) using the Ultralytics library and explore their capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained YOLOv8 model\n",
    "yolov8_nano = YOLO('yolov8n.pt')  # Nano model (smallest)\n",
    "\n",
    "# Alternative models:\n",
    "yolov8_small = YOLO('yolov8s.pt')  # Small model\n",
    "yolov8_medium = YOLO('yolov8m.pt')  # Medium model\n",
    "yolov8_large = YOLO('yolov8l.pt')  # Large model\n",
    "yolov8_xlarge = YOLO('yolov8x.pt')  # Extra large model\n",
    "\n",
    "# Print model information\n",
    "print(\"Available YOLOv8 Models:\")\n",
    "print(f\"Nano Model: {yolov8_nano}\")\n",
    "print(f\"Small Model: {yolov8_small}\")\n",
    "print(f\"Medium Model: {yolov8_medium}\")\n",
    "print(f\"Large Model: {yolov8_large}\")\n",
    "print(f\"Extra Large Model: {yolov8_xlarge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Object Detection\n",
    "Perform object detection on sample images using the pre-trained YOLO model, visualize results with bounding boxes, and extract detailed information about detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a sample image if needed\n",
    "!wget -q https://ultralytics.com/images/bus.jpg -O sample_image.jpg\n",
    "\n",
    "# Perform object detection\n",
    "results = yolov8_nano('sample_image.jpg')\n",
    "\n",
    "# Display results\n",
    "results_image = results[0].plot()\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(results_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('YOLOv8 Detection Results')\n",
    "plt.show()\n",
    "\n",
    "# Extract results data\n",
    "boxes = results[0].boxes\n",
    "\n",
    "# Print detection information\n",
    "print(f\"Number of detections: {len(boxes)}\")\n",
    "print(\"\\nDetection details:\")\n",
    "for i, box in enumerate(boxes):\n",
    "    class_id = int(box.cls.item())\n",
    "    class_name = results[0].names[class_id]\n",
    "    confidence = box.conf.item()\n",
    "    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "    \n",
    "    print(f\"Detection {i+1}: Class: {class_name}, Confidence: {confidence:.2f}, Box: [{int(x1)}, {int(y1)}, {int(x2)}, {int(y2)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Concepts: IoU and NMS\n",
    "Implement Intersection over Union (IoU) calculation and Non-Maximum Suppression (NMS) algorithms to understand how YOLO handles overlapping detections and improves accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection over Union (IoU) Calculation\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between two boxes.\n",
    "    Each box format: [x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "    # Get intersection coordinates\n",
    "    x1_inter = max(box1[0], box2[0])\n",
    "    y1_inter = max(box1[1], box2[1])\n",
    "    x2_inter = min(box1[2], box2[2])\n",
    "    y2_inter = min(box1[3], box2[3])\n",
    "    \n",
    "    # Calculate intersection area\n",
    "    if x2_inter < x1_inter or y2_inter < y1_inter:\n",
    "        return 0.0  # No intersection\n",
    "    \n",
    "    inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)\n",
    "    \n",
    "    # Calculate individual box areas\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area\n",
    "\n",
    "# Example usage\n",
    "box1 = [100, 100, 200, 200]\n",
    "box2 = [150, 150, 250, 250]\n",
    "print(f\"IoU between box1 and box2: {calculate_iou(box1, box2):.4f}\")\n",
    "\n",
    "# Non-Maximum Suppression (NMS)\n",
    "def non_max_suppression(boxes, scores, iou_threshold):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression.\n",
    "    \n",
    "    Args:\n",
    "        boxes: List of bounding boxes [x1, y1, x2, y2]\n",
    "        scores: List of confidence scores\n",
    "        iou_threshold: IoU threshold for considering boxes as duplicates\n",
    "        \n",
    "    Returns:\n",
    "        List of indices of boxes to keep\n",
    "    \"\"\"\n",
    "    # If no boxes, return empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Convert to numpy arrays if they aren't already\n",
    "    if not isinstance(boxes, np.ndarray):\n",
    "        boxes = np.array(boxes)\n",
    "    if not isinstance(scores, np.ndarray):\n",
    "        scores = np.array(scores)\n",
    "    \n",
    "    # Initialize list of picked indices\n",
    "    picked_indices = []\n",
    "    \n",
    "    # Sort score indices in descending order\n",
    "    idxs = np.argsort(scores)[::-1]\n",
    "    \n",
    "    # Loop while we still have indices to process\n",
    "    while len(idxs) > 0:\n",
    "        # Grab the current index with highest score\n",
    "        curr_idx = idxs[0]\n",
    "        picked_indices.append(curr_idx)\n",
    "        \n",
    "        # Find the IoUs for all boxes with the current box\n",
    "        ious = [calculate_iou(boxes[curr_idx], boxes[i]) for i in idxs[1:]]\n",
    "        \n",
    "        # Remove indices with IoU > threshold\n",
    "        idxs = [idxs[i+1] for i, iou in enumerate(ious) if iou <= iou_threshold]\n",
    "    \n",
    "    return picked_indices\n",
    "\n",
    "# Example usage\n",
    "example_boxes = [\n",
    "    [100, 100, 200, 200],\n",
    "    [110, 110, 210, 210],\n",
    "    [150, 150, 250, 250]\n",
    "]\n",
    "example_scores = [0.9, 0.8, 0.7]\n",
    "iou_threshold = 0.5\n",
    "\n",
    "kept_indices = non_max_suppression(example_boxes, example_scores, iou_threshold)\n",
    "print(\"Kept indices after NMS:\", kept_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Video with YOLO\n",
    "Create functions to process video files frame by frame using YOLO for object detection, with options to save the output video containing detection annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a video with YOLO\n",
    "def process_video(video_path, model, output_path, confidence_threshold=0.25, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Process a video file frame by frame using YOLO for object detection.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        model (YOLO): Pre-trained YOLO model.\n",
    "        output_path (str): Path to save the output video with detections.\n",
    "        confidence_threshold (float): Minimum confidence score for detections.\n",
    "        iou_threshold (float): IoU threshold for Non-Maximum Suppression.\n",
    "    \"\"\"\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Create VideoWriter object to save the output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Perform object detection on the frame\n",
    "        results = model(frame, conf=confidence_threshold)\n",
    "        \n",
    "        # Extract bounding boxes, scores, and class IDs\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        scores = results[0].boxes.conf.cpu().numpy()\n",
    "        class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "        \n",
    "        # Apply Non-Maximum Suppression\n",
    "        kept_indices = non_max_suppression(boxes, scores, iou_threshold)\n",
    "        kept_boxes = [boxes[i] for i in kept_indices]\n",
    "        kept_scores = [scores[i] for i in kept_indices]\n",
    "        kept_class_ids = [class_ids[i] for i in kept_indices]\n",
    "        \n",
    "        # Draw detections on the frame\n",
    "        for i, box in enumerate(kept_boxes):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            conf = kept_scores[i]\n",
    "            class_id = int(kept_class_ids[i])\n",
    "            label = f\"{results[0].names[class_id]}: {conf:.2f}\"\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            # Draw label\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # Write the processed frame to the output video\n",
    "        out.write(frame)\n",
    "        \n",
    "        frame_idx += 1\n",
    "        if frame_idx % 100 == 0:\n",
    "            print(f\"Processed {frame_idx}/{total_frames} frames\")\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Video processing complete. Output saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_video_path = \"input_video.mp4\"  # Replace with the path to your input video\n",
    "output_video_path = \"output_video.mp4\"  # Replace with the desired output path\n",
    "process_video(input_video_path, yolov8_nano, output_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Object Detection System\n",
    "Develop a complete real-time object detection system using webcam input, with threading for smooth performance and visualization of detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "class RealTimeObjectDetection:\n",
    "    def __init__(self, model, confidence_threshold=0.5, iou_threshold=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the real-time object detection system.\n",
    "        Args:\n",
    "            model: YOLO model object.\n",
    "            confidence_threshold (float): Minimum confidence score for detections.\n",
    "            iou_threshold (float): IoU threshold for Non-Max Suppression.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.running = False\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Process a single frame with YOLO and draw detections.\n",
    "        Args:\n",
    "            frame: Input video frame.\n",
    "        Returns:\n",
    "            Processed frame with detections drawn.\n",
    "        \"\"\"\n",
    "        results = self.model(frame, conf=self.confidence_threshold)\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        scores = results[0].boxes.conf.cpu().numpy()\n",
    "        class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "        # Apply Non-Maximum Suppression\n",
    "        kept_indices = non_max_suppression(boxes, scores, self.iou_threshold)\n",
    "        kept_boxes = [boxes[i] for i in kept_indices]\n",
    "        kept_scores = [scores[i] for i in kept_indices]\n",
    "        kept_class_ids = [class_ids[i] for i in kept_indices]\n",
    "\n",
    "        # Draw detections on the frame\n",
    "        for i, box in enumerate(kept_boxes):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            conf = kept_scores[i]\n",
    "            class_id = int(kept_class_ids[i])\n",
    "            label = f\"{results[0].names[class_id]}: {conf:.2f}\"\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            # Draw label\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def start_detection(self, video_source=0):\n",
    "        \"\"\"\n",
    "        Start real-time object detection using a webcam or video file.\n",
    "        Args:\n",
    "            video_source: Video source (default is webcam, use file path for video).\n",
    "        \"\"\"\n",
    "        self.running = True\n",
    "        cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "        while self.running and cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Process the frame\n",
    "            processed_frame = self.process_frame(frame)\n",
    "\n",
    "            # Display the frame\n",
    "            cv2.imshow(\"Real-Time Object Detection\", processed_frame)\n",
    "\n",
    "            # Exit on 'q' key press\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                self.running = False\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def stop_detection(self):\n",
    "        \"\"\"\n",
    "        Stop the real-time object detection.\n",
    "        \"\"\"\n",
    "        self.running = False\n",
    "\n",
    "# Example usage\n",
    "real_time_detector = RealTimeObjectDetection(yolov8_nano, confidence_threshold=0.6, iou_threshold=0.4)\n",
    "\n",
    "# To use the detector, run these commands in separate cells:\n",
    "# 1. Start detection: detection_thread = Thread(target=real_time_detector.start_detection, args=(0,))\n",
    "# 2. Start the thread: detection_thread.start()\n",
    "# 3. Stop detection after use: real_time_detector.stop_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Counting and Alerting\n",
    "Extend the real-time detection system to count detected objects by class and implement an alerting mechanism for specific object classes of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeObjectDetectionWithAlerts(RealTimeObjectDetection):\n",
    "    def __init__(self, model, confidence_threshold=0.5, iou_threshold=0.5, alert_classes=None):\n",
    "        \"\"\"\n",
    "        Extend the real-time object detection system to include object counting and alerting.\n",
    "        Args:\n",
    "            model: YOLO model object.\n",
    "            confidence_threshold (float): Minimum confidence score for detections.\n",
    "            iou_threshold (float): IoU threshold for Non-Max Suppression.\n",
    "            alert_classes (list): List of class IDs to trigger alerts for.\n",
    "        \"\"\"\n",
    "        super().__init__(model, confidence_threshold, iou_threshold)\n",
    "        self.alert_classes = alert_classes if alert_classes else []\n",
    "\n",
    "    def process_frame_with_alerts(self, frame):\n",
    "        \"\"\"\n",
    "        Process a single frame with YOLO, count objects, and trigger alerts.\n",
    "        Args:\n",
    "            frame: Input video frame.\n",
    "        Returns:\n",
    "            Processed frame with detections drawn and alerts triggered.\n",
    "        \"\"\"\n",
    "        results = self.model(frame, conf=self.confidence_threshold)\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        scores = results[0].boxes.conf.cpu().numpy()\n",
    "        class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "        # Apply Non-Maximum Suppression\n",
    "        kept_indices = non_max_suppression(boxes, scores, self.iou_threshold)\n",
    "        kept_boxes = [boxes[i] for i in kept_indices]\n",
    "        kept_scores = [scores[i] for i in kept_indices]\n",
    "        kept_class_ids = [class_ids[i] for i in kept_indices]\n",
    "\n",
    "        # Count objects by class and check for alert classes\n",
    "        class_counts = {}\n",
    "        alert_count = 0\n",
    "        for i, class_id in enumerate(kept_class_ids):\n",
    "            class_name = results[0].names[int(class_id)]\n",
    "            if class_name in class_counts:\n",
    "                class_counts[class_name] += 1\n",
    "            else:\n",
    "                class_counts[class_name] = 1\n",
    "\n",
    "            if int(class_id) in self.alert_classes:\n",
    "                alert_count += 1\n",
    "\n",
    "        # Draw detections on the frame\n",
    "        for i, box in enumerate(kept_boxes):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            conf = kept_scores[i]\n",
    "            class_id = int(kept_class_ids[i])\n",
    "            label = f\"{results[0].names[class_id]}: {conf:.2f}\"\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            # Draw label\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Display object counts on the frame\n",
    "        y_offset = 30\n",
    "        for class_name, count in class_counts.items():\n",
    "            text = f\"{class_name}: {count}\"\n",
    "            cv2.putText(frame, text, (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "            y_offset += 30\n",
    "\n",
    "        # Trigger alert if needed\n",
    "        if alert_count > 0:\n",
    "            alert_text = f\"ALERT: {alert_count} objects of interest detected!\"\n",
    "            cv2.putText(frame, alert_text, (10, frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            print(alert_text)\n",
    "\n",
    "        return frame\n",
    "\n",
    "# Example usage\n",
    "alert_classes = [0, 1]  # Replace with class IDs of interest\n",
    "real_time_detector_with_alerts = RealTimeObjectDetectionWithAlerts(\n",
    "    yolov8_nano, confidence_threshold=0.6, iou_threshold=0.4, alert_classes=alert_classes\n",
    ")\n",
    "\n",
    "# To use the detector with alerts, run these commands in separate cells:\n",
    "# 1. Start detection: detection_thread = Thread(target=real_time_detector_with_alerts.start_detection, args=(0,))\n",
    "# 2. Start the thread: detection_thread.start()\n",
    "# 3. Stop detection after use: real_time_detector_with_alerts.stop_detection()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
